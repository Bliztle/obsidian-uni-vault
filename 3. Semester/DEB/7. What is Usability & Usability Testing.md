[](Pasted%20image%2020230924193155.png)![](Pasted%20image%2020230924205614.png)
Related to adjusting envisionment or physical design

## What is usability?
![](Pasted%20image%2020230924193231.png)
Questions:![](Pasted%20image%2020230924193323.png)

## What is usability testing
The study of users’ interaction with a product, service or artefact.

Purpose
• Identifying usability problems in a system
• Starting point for refinements of design

Outcome
• A ranked list of usability problems
• Knowledge about what works well

### How do we evaluate usability?

Inquiry
- Pact analysis helps ensure we can design tasks that fit within the context of the users

#### More formally
Testing
- People using envisioned version of system
Inspection
- Testing of envisioned design by expert - UX / Usability expert, not designer
Data analytics
- eg. google analytics / facebook analytics
## When to test
![](Pasted%20image%2020230924195948.png)
Exploratory
- Formative test
- Helps choose / design features
Assessment test
- Summative
- Meassure usability of user accomplishing tasks or looking for deficiencies
Validation test
- validates earlier issues
Comparison test
- Called AB testing
- Compare two or more designs to identy strenghts / weaknesses
- Multiple options help users explain
- During detail design - About smaller changes / how to represent data

#### Lab vs field test
Controlled testing for singular variable vs conducting tests in the real world
![](Pasted%20image%2020230924200547.png)
- Communication behind the scene
	- Observers can comm while it happens
- Demand characteristics
	- Controller can put user into a certain mindset

#### Types of testing
Both produce ranked list of usability problems

Usability testing
- Representative users interact with design while thinking out loud
- Slow but detailed
- Lab test

Heuristic inspection'
- Usability expert inspects using checklist (heuristic)
- Quick and easy - no user involved
- 3-5 inspections (multiple experts) find ~70% of problems
- Can find "cosmetic" problems
- also finds "false" usability problems

## Planning
#### Different perspectives
![](Pasted%20image%2020230924201508.png)
![](Pasted%20image%2020230924201523.png)
#### Activites
![](Pasted%20image%2020230924201555.png)

### Context of use
Where is the design/system used?
• Physical environment?
• Social context?

Who uses the design?
• User profiles

Why is the design used?
• What do people use it for?
• Work? Leisure? Other activities?

How is the design used?
• Typical interactions
• Relevant and realistic data (what can we obtain?)

Lab / field is a spectrum, and labs can be set up to mimic the real world. Field may add risk.

#### Test Participants
Representative for the user group
• Demographics
• Experience - How well should they know product / context? Expectation about participant

Number of test subjects - after 6-8 users -> Diminishing returns
• Generalisability
• Quantitative conclusions - What can we conclude?
• Statistics - Enough participants allow this

Using fellow students - Rarely but sometimes relevant
• Problematic…
• Motivation - Why are students helping us? How does it affect results
		 - Do we end up with mostly students who already have knowledge
		 - Do the students even represent user base?
• Demographics and experience
![](Pasted%20image%2020230924202208.png)
Tim recommends 5-10 but depending on subject. Discuss with supervisor

### Deciding on the task
What are the basic tasks that representative users do with the system?
- Is the whole system part of the evaluation?
- Can we create a crystal clear task description?
- How long does it take to solve tasks?
Some useful rules for defining tasks:
1. Make the Tasks Realistic
2. Make the Tasks Actionable
3. Avoid Clues and Describing the Steps

Good tasks
- Represent real use of the system
- Describe the end result
- Motivate (why should they be solved?)
- Include relevant data (e.g. names) - Provide login. Don't ask users to enter own information
- Group smaller sub-tasks together

Typical problems
- Vague, unclear or general
- Provides too much help
- Contain jargon and unfamiliar terms
- Forces the user into a specified sequence
- More info: https://www.nngroup.com/articles/task-scenarios-usability-testing/
![](Pasted%20image%2020230924202735.png)

### Examples
Focusing on "easy to learn" or "efficient to use"
![](Pasted%20image%2020230924202903.png)
#rubin #chisnell  ![](Pasted%20image%2020230924202919.png)
## Conducting

### The usability laboratory
![](Pasted%20image%2020230924215049.png)
Cassiopea has room for this
- Hidden cameras and microphones
- Pre-intalled recording software
![](Pasted%20image%2020230924215217.png)![](Pasted%20image%2020230924215242.png)
General equipment
- Motorized cameras
- PC screen capture
- Camera remote control
- Video monitors
- Video mixer Quad-splitter
- Microphones
- Video recorders (solid state/usb)
- etc…

Replicate simple version in group room
- Don't overcrowd
- Prepare neat space
- Recording software - obs / webcam
- Bring refreshments to feel comfortable 

##### Test moderator / monitor
The person sitting with the subject
![](Pasted%20image%2020230924215658.png)

### Conducting in practice
- Introduce the test
	- Today you will...
	- The name of the program is ...
	- Initially you will try to complete x tasks using...
		- How will it work?
	- By participating you agree that ...
		- Explicitly ask for consent - ***MOODLE EXAMPLE***
		- Stress that it is voluntary - ***IMPORTANT***
	- Thank you in advance for your time, we really appreciate your help!
- Make user think aloud
	- Participants need to be explained what this means![](Pasted%20image%2020230924220334.png)
	- The data we want to get:
		- "I want to do..."
		- "I’m looking at the UI, and I think it does…"
		- "Hmm, that’s not what I expected; I thought it was going to…"
		- "hat took longer than I expected, I was trying to do ..."
	- Test monitor may provide a little help
	- Observer takes notes and makes log file
- Debriefing
	- Do this right after!![](Pasted%20image%2020230924220518.png)