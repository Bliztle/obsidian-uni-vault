![](Pasted%20image%2020240424094527.png)
Yep yep
The first two lines can be executed independently of each other, and both rely on IO. Beneficial for both uni- and multi-core
![](Pasted%20image%2020240424094731.png)
![](Pasted%20image%2020240424094929.png)
$\{-1,3,6\}\times\{24,27,31\}$

![](Pasted%20image%2020240424095344.png)
```c
pthread_mutex_lock(from_lock);
*from-=amount;
pthread_mutex_unlock(from_lock);
pthread_mutex_lock(to_lock);
*to+=amount;
pthread_mutex_unlock(to_lock);
```
![](Pasted%20image%2020240424095801.png)
```c
pthread_mutex_t from_lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t to_lock = PTHREAD_MUTEX_INITIALIZER;

int transfer(int *from, int *to, int amount) {
	pthread_mutex_lock(&from_lock);
	if (amount < 0 || *from<amount)
		return 0;
	*from-=amount;
	pthread_mutex_unlock(&from_lock);
	pthread_mutex_lock(&to_lock);
	*to+=amount;
	pthread_mutex_unlock(&to_lock);
	return 1;
}
```
![](Pasted%20image%2020240424100317.png)
```c
#include <pthread.h>
#include <stdio.h>

pthread_mutex_t lock1 = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t lock2 = PTHREAD_MUTEX_INITIALIZER;

int account1 = 10;
int account2 = 20;

int transfer(int *from, int *to, int amount, pthread_mutex_t *lock1,
             pthread_mutex_t *lock2) {
  pthread_mutex_lock(lock1);
  if (amount < 0 || *from < amount) {
    pthread_mutex_unlock(lock1);
    return 0;
  }
  *from -= amount;
  pthread_mutex_unlock(lock1);
  pthread_mutex_lock(lock2);
  *to += amount;
  pthread_mutex_unlock(lock2);
  return 1;
}

void *thread_transfer(void *_args) {
  int **args = (int **)_args;
  int *from = args[0];
  int *to = args[1];
  int amount = *args[2];
  pthread_mutex_t *lock1 = (pthread_mutex_t *)((void **)_args)[3];
  pthread_mutex_t *lock2 = (pthread_mutex_t *)((void **)_args)[4];
  transfer(from, to, amount, lock1, lock2);
  return NULL;
}

int main() {
  pthread_t t1, t2;
  int amount1 = 5;
  void *args1[5] = {&account1, &account2, &amount1, &lock1, &lock2};
  int amount2 = 15;
  void *args2[5] = {&account2, &account1, &amount2, &lock1, &lock2};
  pthread_create(&t1, NULL, thread_transfer, (void *)args1);
  pthread_create(&t2, NULL, thread_transfer, (void *)args2);
  pthread_join(t1, NULL);
  pthread_join(t2, NULL);
  printf("Account 1: %d\n", account1);
  printf("Account 2: %d\n", account2);
  return 0;
}
```
![](Pasted%20image%2020240424104336.png)
Yep
![](Pasted%20image%2020240424104353.png)
###### 3.1
```c
int get(counter_t *c) {
	pthread_mutex_lock(&c->glock);
	int val = c->global;
	for(int i = 0; i<NUMCPUS; i++) {
		pthread_mutex_lock(&c->llock[i]);
		val += c->local[i];
	}
	pthread_mutex_unlock(&c->glock);
	for(int i = 0; i<NUMCPUS; i++) {
		pthread_mutex_unlock(&c->llock[i]);
	}
	return val; // only approximate!
}
```
###### 3.2
Performance is not great, as it relies on locking all counters at once. Should be alright though, as there are only 2 threads competing at a time.
- More threads would worsen performance
- It performs alright assuming  `{c}pthread_mutex_lock` queues lock requests, but otherwise it may starve multiple threads.
	- If later locks are slow to get access, first counters are deadlocked for a long time

We wrote the code. It doesn't work
![](Pasted%20image%2020240424111316.png)![](Pasted%20image%2020240424111427.png)

| Variable instance | Main thread | Peer thread 0      | Peer thread 1      |
| ----------------- | ----------- | ------------------ | ------------------ |
| ptr               | yes         | yes                | yes                |
| cnt               | no          | yes                | yes                |
| i.m               | yes         | no (pass-by-value) | no (pass-by-value) |
| msgs.m            | yes         | yes                | yes                |
| myid.p0           | no          | yes                | no                 |
| myid.p1           | no          | no                 | yes                |
![](Pasted%20image%2020240424112746.png)
1) There are no read and writes to the same location. All threads have distinct areas they write to.
2) You pay the price of starting new threads for no real benefit, as they will be stealing #CPU time from each other. Realistically though, this happens earlier, as there are many other processes running already.
3) 