## Storage Technologies
#cspp/6-1 
#### Random Access Memory #RAM
Two versions
![](Pasted%20image%2020240326160937.png)
- Static ram #SRAM
	- Significantly faster and more expensive
	- Caches both on and off #CPU chip
	- 10s of mb
	- Stored in *bistable* memory cell. Any middle state will quickly move to either stable voltage.
		- Disturbances bounce it away but comes back, without shifting
- Dynamic ram #DRAM
	- Main memory and graphics system frame buffer
	- Not disturbance resistant
	- Stored in capacity, with a 10-100ms grace period should power be lost
#DRAM is partitioned into $d$ supercells of $w$ #DRAM cells, giving a $d\times w$ #DRAM cells arranged in a rectangular grid
- Accessed via *pins* (one-bit signals). *Memory controller* reads/writes $w$ bits at a time, after converting an incoming address to pair $(j,i)$
- ![](Pasted%20image%2020240326161952.png)
- For $(i,j)$, $i$ is #RAS (row access strobe) request, $j$ si #CAS (column access strobe) request
###### Enhanced #DRAM 
#cspp/6-1-1/p622 has list of improvements
- Sync using clocksignals rising edge is faster
	- #DDR is 2x, using both clock signal edges
###### Nonvolatile memory
- #PROM (programmable) can be set once on creation with a fuse
	- May store firmware
- #EPROM (erasable) can be reset ~1000 times with ultraviolet light
- #EEPROM (electrically) doesn't require other physical device
- Flash memory like #SSD is based on #EEPROM
###### Reading memory
![](Pasted%20image%2020240326170249.png)
- I/O-bridge includes memory controller
![](Pasted%20image%2020240326163131.png)
###### Solid state drive #SSD
#cspp/6-1-3 
*Flash transaction layer* plays *disk controller*
*Reading > writing*
![](Pasted%20image%2020240326163447.png)
After enough writes, disk cannot be used any more.
#### Locality
#cspp/6-2 *Programs with good locality run faster*
The *principle of locality* states
> Well-written computer programs tend to exhibit good locality. That is, they tend to reference data items that are near other recently referenced data items or that were recently referenced themselves
- *Spacial locality*
	- if referenced, nearby memory will be referenced as well
	- *Stride-$k$ reference pattern*
		- visiting every $k$ element. As #stride increases, spacial locality decreases
	- Good 2x loops read in *major row order*
	- less jumping provides better locality for instruction fetching
- *Temporal locality*
	- If referenced, will be referenced again soon
#### Memory Hierarchy
#cspp/6-3
![](Pasted%20image%2020240326164530.png) ![](Pasted%20image%2020240417092930.png)![](Pasted%20image%2020240326164902.png)
- Data is copied in block sizes (*data transfer units*) determined by the (L$k$, L$k+1$) pair, not L$k$ itself
- *Cache hit* - Finding data object $d$ from $k+1$ in $k$
- *Cache miss* - not in $k$, $k$ fetches and caches from $k+1$, *evicting* some other data
	- *Least recently used* #LRU is a strategy
###### Kinds of misses
*compulsory miss / cold miss* - Cache is empty
*conflict miss* - higher caches need faster replacement strategy, so a block may be assigned a set of blocks on $k+1$. 
- When there was room, but wasn't cached due to strategy
###### Cache Management
![](Pasted%20image%2020240326165624.png)
#### Cache Memories
#cspp/6-4
![](Pasted%20image%2020240326170255.png)
- L1 installed in chip, to let storage keep up
	- #CPU improve multiple orders of magnitudes faster than #RAM 
###### Generic cache memory Organization
#cspp/6-4-1 
$M=2^m$ bits split in $S=2^s$ *cache sets*
represented by the tuple $(S, E, B, m)$
- $S:$ Size of cache
- $C:$ cache
- $E:$ cache lines with data block $B$, a *valid bit* (whether data has meaning), and $t=m-(b+s)$ tag bits
- $B:$ Data block of $B=2^b$ bits
![](Pasted%20image%2020240326171653.png)![](Pasted%20image%2020240326171720.png)
Checking if cache has copy of address $A$
- $s$ *set index* bits tell which set to look in
- $t$ says which line
	- *hit* if *valid bit* is set, and cache *t* matches *address* *t*
![](Pasted%20image%2020240326172527.png)
###### Direct-Mapped Caches
#cspp/6-4-2 
*single line cache*, $E=1$
![](Pasted%20image%2020240326172538.png)
3 steps when determining hit/miss
1. Set selection - Extract S bits as uint, that is the set number
2. Line matching - Check *valid bit* and if *t* match
3. Word selection - block offset says where word should start
4. On miss: Line replacement - replace current line with data after fetch, as there is only 1 in single line cache
	1. Replaces entire line, so adjacent words may be cached as well
![](Pasted%20image%2020240326172843.png)![](Pasted%20image%2020240326173308.png)
###### Conflic misses in Direct-Mapped caches
```c
for (int i = 0; i < 8; i++)
	sum += x[i] * y[i]
```
May be slow if x/y have addresses mapping the same set, always missing.
 - Fix by adding offset
###### Set Associative Cache
#cspp/6-4-3 $1<E<\frac{C}{B}\rightarrow E$-way set associative cache
![](Pasted%20image%2020240326174010.png)
Multiple lines, check multiple *t*'s. Replacement is random, #LRU or #LFU (least frequently used)
###### Fully associative caches
#cspp/6-4-3 $E=\frac{C}{B}$
Single set, since tag maps to line
![](Pasted%20image%2020240326174348.png)
![](Pasted%20image%2020240410082130.png)
Reading i.e. a long which is not aligned might require multiple blocks to be cached, possibly giving multiple cache misses.
###### Writing
- *write-through* writing through all layers is simple but expensive
- *write-back* defers writing 'till line is needed. Complicated but needs less bus-traffic
*Write misses* where address is not cached below are hard
#### Writing cache-friendly code
#cspp/6-5 *common case first & minimal misses in inner loop*
