## Principles of Pipelining
#cspp/4-4
###### Without a pipeline
![](Pasted%20image%2020240319173608.png)
![](Pasted%20image%2020240319173640.png)
###### With a pipeline
![](Pasted%20image%2020240319173803.png)![](Pasted%20image%2020240319174012.png)
This gets throughput of $8.33$ GIPS
#### Pipeline limitations
#cspp/4-4-3
Nonuniform Partitioning
- If each stage takes different amount of times, each cycle is bottlenecked by the slowest
Diminishing returns
- with 50ps/20ps split, doubling from 3 to 6 pipelines yields $1.71$x throughput
Logical dependencies
- Operations depending on other operations may slow down, if the first has to end before the next can start
- Jumping gives unpredictable control flow
#### Performance Analysis
#cspp/4-5-9
***C**ycles **P**er **I**nstruction* #CPI
$C_{i}=$ instruction cycle
$C_{b}=$ instruction bubble (no instruction processed)
$CPI=\frac{C_{i}+C_{b}}{C_{i}}=\frac{1.0+C_{b}}{C_{i}}$

Three penalty types injects bubbles:
- Load penalty $lp$ (`mrmovq` & `popq`)
- Mispredicted branch penalty $mp$ (conditional jump)
- Return penalty $rp$ (`ret`)
![](Pasted%20image%2020240319175654.png)
## Optimising Program Performance
#cspp/5
*Optimisations may never change behaviour*
The following are not equal, in the case the pointers are the same (*memory aliasing*)
```c
void twiddle1(long *xp, long *yp)
{
  *xp += *yp;
  *xp += *yp;
}

void twiddle2(long *xp, long *yp)
{
  *xp += 2* *yp;
}
```
###### Common optimisation blockers
1. Memory aliasing
2. Function calls - repeated calls may not be optimised, as function may have sideeffects
#### Expressing performance
#cspp/5-2
***C**ycles **P**er **E**element* #CPE - For understanding loop performance
- *Loop unrolling* #cspp/5-2 may increase performance, handling 2+ elements per iteration, giving less clock cycles
- *code motion* #cspp5-4 moves function calls out of loop if value is not expected to change
- *Reducing procedure calls* #cspp/5-5 may also remove overhead, giving direct access to data, instead of always through protected procedure with checks. Requires previous analysis to determine it will not cause issues.
- *Eliminating pointer references* #cspp/5-6 keep value in register (local variable) instead of pointer while computing, and only set pointer in the end. Ensure however that this doesn't cause any issues.
	- Below stores value at the end. Bottom is much faster, but different result (though maybe correct???)
		- ![](Pasted%20image%2020240319183402.png)
	- Example is contrived and happens because the destination is a *memory alias* for the last element.
![](Pasted%20image%2020240319183900.png)![](Pasted%20image%2020240319183917.png)

| Function | Time (cycles?) |
| -------- | -------------- |
| combine1 | $20.18$        |
| combine4 | $5.01$         |
#### Understanding modern processors
*Further optimisations require knowledge of target architecture*
- *Latency bound* - operations dependant in sequence
- *throughput bound* - raw capacity of #CPU functional units
	- The final limit on program performance
![](Pasted%20image%2020240319184322.png)
- *Branch prediction* with *speculative execution* starts executing branch, resetting and diverting if prediction is wrong.
- *Instruction decoding* turns instruction into *microoperations* for the #EU to give *functional units*
	- Example machine has 8 units:
	- ![](Pasted%20image%2020240319184759.png)
- Results from *functional units* after *predictions* are kept in FIFO queue until *retired* (on success) or *flushed* (on wrong prediction)
	- This way no change is made on error, as it never leaves #EU before confirmation
- *Register renaming* moves data between *execution units* by adding tuple $(r,t)$ to a table saying *"Update register r with value tagged t"*, which happens when a *functional unit* sends value tuple $(v,t)$.
###### Functional Unit Performance
#cspp/5-7-2 
![](Pasted%20image%2020240319190506.png)
- Each unit is internally pipelined
	- Floating point multiplication has 3 stages, hence *latency* 3
	- *Issue time* 1 means it is *fully pipelined*
		- Multiplication can start each cycle, even though it takes 3 to complete
*Throughput* $=\frac{1}{issue\ time}$
![](Pasted%20image%2020240319190951.png)
###### Abstract Processor Operation Model
#cspp/5-7-3 
*data-flow* represents programs in graphical notation with dependencies on operation constraints from order of execution
- *Critical paths* found in constraints put lower bound on # of clock cycles required
![](Pasted%20image%2020240319192434.png)![](Pasted%20image%2020240319192341.png)
*Assembler for the inside of a loop in example, and corresponding graph*
![](Pasted%20image%2020240319192639.png)![](Pasted%20image%2020240319193020.png)
*Multiplication forms critical path, as latency is 5 cycles, as opposed to 1 add*
#### Loop Unrolling 
#cspp/5-8 
*decreases* #CPE
- $k\times1$ *loop unrolling* - Handling $k$ elements per iteration
	- Need to stop loop early and handle remaining $<k$ elements after
	- Cannot improve beyond *latency bound* found with *critical path*
		- Only improves actual looping mechanism
#cspp/5-9 
- $k\times j$ *loop unrolling*
	- Splitting accumulators from 1 to $j$, i.e. multiplying even indicies in one register, and odds in another for $2\times2$ *unrolling*
![](Pasted%20image%2020240319194128.png)
Yields #CPE $\frac{5\ per\ mul}{2\ elements\ per\ mul}=2.5$
![](Pasted%20image%2020240319194345.png)
###### Reassociation Transformation
#cspp/5-9-2 *Moving parenthesis to reduce loads*
changing from 1 to 2:
1. $acc=(acc\ \texttt{OP}\ data[i])\ \texttt{OP}\ data[i+1]$
2. $acc=acc\ \texttt{OP}\ (data[i]\ \texttt{OP}\ data[i+1])$
only loads data 2 times now
![](Pasted%20image%2020240319195139.png)
#### Summarising optimisation
#cspp/5-10 
![](Pasted%20image%2020240319195246.png)
## Program Profiling
#cspp/5-14
unix (though not nix) comes with `GPROF`
1. Compile without inline optimisations
	1. `gcc -Og -pg prog.c -o prog`
2. Run program, which is slightly slower due to flags
	1. `./prog`
	2. produces `gmon.out`
3. invoke `GPROF` which analyses `gmon.out`
	1. `gprof prog`
Output is in multiple parts
1. Functions and how long they ran (`calls` counts non-recursive)
	1. ![](Pasted%20image%2020240319200234.png)
2. call history
	1. ![](Pasted%20image%2020240319200311.png)
- Timing is not very precise. At interval $\delta$ it is checked which function is running, and it is granted $\delta$ time
- Calling information is precise, assuming no inline substitutions for functions
- Timings for libraries are not shown by default
#### How to
1. Scan to find bottleneck
2. Improve bottleneck
3. Now a new part might bottle the operation
4. Back to 1